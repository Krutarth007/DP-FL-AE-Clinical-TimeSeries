{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98f914c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 13:08:53,800 - INFO - (PID 24332) - === Phase 1: Data Loading (Multi-Feature) ===\n",
      "2025-12-07 13:08:53,813 - INFO - (PID 24332) - Processing up to 5000 FHIR files from directory: C:\\mimic-iv-2.2\\mimic_fhir_5000_output\n",
      "2025-12-07 13:15:20,119 - INFO - (PID 24332) - Successfully loaded and combined data from 2889 unique patients.\n",
      "2025-12-07 13:15:20,215 - INFO - (PID 24332) - === Phase 2: Data Preprocessing (Multi-Feature) ===\n",
      "2025-12-07 13:15:20,247 - WARNING - (PID 24332) - Removed 30 rows containing final NaNs before sequence creation.\n",
      "2025-12-07 13:15:46,064 - INFO - (PID 24332) - Total training sequences generated: 30417\n",
      "2025-12-07 13:15:46,066 - INFO - (PID 24332) - Total validation sequences generated: 6086\n",
      "2025-12-07 13:15:46,076 - INFO - (PID 24332) - === Phase 3: Optimized Multi-Model Training (Centralized and Federated) ===\n",
      "2025-12-07 13:15:46,078 - INFO - (PID 24332) - --- Training Conv1D-AE ---\n",
      "2025-12-07 13:15:49,991 - INFO - (PID 24332) -     Starting Centralized training for Conv1D-AE...\n",
      "2025-12-07 13:17:51,273 - INFO - (PID 24332) - Centralized Conv1D-AE completed. RMSE: 10.9287\n",
      "2025-12-07 13:17:51,395 - INFO - (PID 24332) - Starting optimized federated training for Conv1D-AE...\n",
      "2025-12-07 13:18:25,856 - INFO - (PID 24332) - Round 1: Train RMSE = 1.7142, Val RMSE = 20.4881, Time = 34.5s\n",
      "2025-12-07 13:18:58,590 - INFO - (PID 24332) - Round 2: Train RMSE = 1.6785, Val RMSE = 19.3285, Time = 32.7s\n",
      "2025-12-07 13:19:30,559 - INFO - (PID 24332) - Round 3: Train RMSE = 1.6631, Val RMSE = 18.5841, Time = 32.0s\n",
      "2025-12-07 13:20:03,696 - INFO - (PID 24332) - Round 4: Train RMSE = 1.6558, Val RMSE = 18.2194, Time = 33.1s\n",
      "2025-12-07 13:20:36,540 - INFO - (PID 24332) - Round 5: Train RMSE = 1.6457, Val RMSE = 17.0605, Time = 32.8s\n",
      "2025-12-07 13:21:09,519 - INFO - (PID 24332) - Round 6: Train RMSE = 1.6368, Val RMSE = 16.4814, Time = 33.0s\n",
      "2025-12-07 13:21:42,925 - INFO - (PID 24332) - Round 7: Train RMSE = 1.6255, Val RMSE = 15.9004, Time = 33.4s\n",
      "2025-12-07 13:22:16,618 - INFO - (PID 24332) - Round 8: Train RMSE = 1.6141, Val RMSE = 15.8191, Time = 33.7s\n",
      "2025-12-07 13:22:49,700 - INFO - (PID 24332) - Round 9: Train RMSE = 1.6067, Val RMSE = 15.5181, Time = 33.1s\n",
      "2025-12-07 13:23:21,602 - INFO - (PID 24332) - Round 10: Train RMSE = 1.6031, Val RMSE = 14.4176, Time = 31.9s\n",
      "2025-12-07 13:23:54,364 - INFO - (PID 24332) - Round 11: Train RMSE = 1.6023, Val RMSE = 14.6282, Time = 32.8s\n",
      "2025-12-07 13:24:27,386 - INFO - (PID 24332) - Round 12: Train RMSE = 1.7760, Val RMSE = 21.3285, Time = 33.0s\n",
      "2025-12-07 13:25:00,144 - INFO - (PID 24332) - Round 13: Train RMSE = 1.5795, Val RMSE = 14.4658, Time = 32.8s\n",
      "2025-12-07 13:25:32,166 - INFO - (PID 24332) - Round 14: Train RMSE = 1.5731, Val RMSE = 13.5895, Time = 32.0s\n",
      "2025-12-07 13:26:05,472 - INFO - (PID 24332) - Round 15: Train RMSE = 1.7765, Val RMSE = 21.2509, Time = 33.3s\n",
      "2025-12-07 13:26:37,783 - INFO - (PID 24332) - Round 16: Train RMSE = 1.7798, Val RMSE = 21.3799, Time = 32.3s\n",
      "2025-12-07 13:27:10,940 - INFO - (PID 24332) - Round 17: Train RMSE = 1.7826, Val RMSE = 21.4392, Time = 33.2s\n",
      "2025-12-07 13:27:41,161 - INFO - (PID 24332) - Round 18: Train RMSE = 1.7852, Val RMSE = 21.4802, Time = 30.2s\n",
      "2025-12-07 13:28:12,519 - INFO - (PID 24332) - Round 19: Train RMSE = 1.7838, Val RMSE = 21.5066, Time = 31.4s\n",
      "2025-12-07 13:28:44,219 - INFO - (PID 24332) - Round 20: Train RMSE = 1.7847, Val RMSE = 21.5704, Time = 31.7s\n",
      "2025-12-07 13:29:15,533 - INFO - (PID 24332) - Round 21: Train RMSE = 1.7890, Val RMSE = 21.7528, Time = 31.3s\n",
      "2025-12-07 13:29:47,500 - INFO - (PID 24332) - Round 22: Train RMSE = 1.7884, Val RMSE = 21.9626, Time = 32.0s\n",
      "2025-12-07 13:30:17,897 - INFO - (PID 24332) - Round 23: Train RMSE = 1.7884, Val RMSE = 22.0307, Time = 30.4s\n",
      "2025-12-07 13:30:48,204 - INFO - (PID 24332) - Round 24: Train RMSE = 1.7883, Val RMSE = 22.0579, Time = 30.3s\n",
      "2025-12-07 13:31:17,881 - INFO - (PID 24332) - Round 25: Train RMSE = 1.7901, Val RMSE = 22.2717, Time = 29.7s\n",
      "2025-12-07 13:31:48,374 - INFO - (PID 24332) - Round 26: Train RMSE = 1.7941, Val RMSE = 22.4356, Time = 30.5s\n",
      "2025-12-07 13:32:19,123 - INFO - (PID 24332) - Round 27: Train RMSE = 1.8009, Val RMSE = 22.8267, Time = 30.7s\n",
      "2025-12-07 13:32:50,796 - INFO - (PID 24332) - Round 28: Train RMSE = 1.8001, Val RMSE = 22.7118, Time = 31.7s\n",
      "2025-12-07 13:33:21,855 - INFO - (PID 24332) - Round 29: Train RMSE = 1.8000, Val RMSE = 22.6780, Time = 31.1s\n",
      "2025-12-07 13:33:21,857 - INFO - (PID 24332) - Federated training stopped early at round 29.\n",
      "2025-12-07 13:33:21,861 - INFO - (PID 24332) - Federated Conv1D-AE completed. RMSE: 13.5895\n",
      "2025-12-07 13:33:21,862 - INFO - (PID 24332) - --- Training BiLSTM-AE ---\n",
      "2025-12-07 13:33:24,180 - INFO - (PID 24332) -     Starting Centralized training for BiLSTM-AE...\n",
      "2025-12-07 14:28:03,419 - INFO - (PID 24332) - Centralized BiLSTM-AE completed. RMSE: 9.6116\n",
      "2025-12-07 14:28:05,491 - INFO - (PID 24332) - Starting optimized federated training for BiLSTM-AE...\n",
      "2025-12-07 14:32:52,861 - INFO - (PID 24332) - Round 1: Train RMSE = 1.7836, Val RMSE = 20.3179, Time = 287.4s\n",
      "2025-12-07 14:36:52,446 - INFO - (PID 24332) - Round 2: Train RMSE = 1.7107, Val RMSE = 19.2732, Time = 239.6s\n",
      "2025-12-07 14:41:56,400 - INFO - (PID 24332) - Round 3: Train RMSE = 1.6599, Val RMSE = 18.5219, Time = 304.0s\n",
      "2025-12-07 14:46:06,341 - INFO - (PID 24332) - Round 4: Train RMSE = 1.6436, Val RMSE = 16.8564, Time = 249.9s\n",
      "2025-12-07 14:50:12,421 - INFO - (PID 24332) - Round 5: Train RMSE = 1.6098, Val RMSE = 15.3297, Time = 246.1s\n",
      "2025-12-07 14:54:14,573 - INFO - (PID 24332) - Round 6: Train RMSE = 1.5830, Val RMSE = 15.2101, Time = 242.2s\n",
      "2025-12-07 14:59:50,997 - INFO - (PID 24332) - Round 7: Train RMSE = 1.5868, Val RMSE = 15.3111, Time = 336.4s\n",
      "2025-12-07 15:05:37,954 - INFO - (PID 24332) - Round 8: Train RMSE = 1.5596, Val RMSE = 14.4490, Time = 347.0s\n",
      "2025-12-07 15:09:41,884 - INFO - (PID 24332) - Round 9: Train RMSE = 1.5445, Val RMSE = 14.3490, Time = 243.9s\n",
      "2025-12-07 15:13:52,587 - INFO - (PID 24332) - Round 10: Train RMSE = 1.5363, Val RMSE = 13.5085, Time = 250.7s\n",
      "2025-12-07 15:18:01,504 - INFO - (PID 24332) - Round 11: Train RMSE = 1.5250, Val RMSE = 13.9797, Time = 248.9s\n",
      "2025-12-07 15:21:48,674 - INFO - (PID 24332) - Round 12: Train RMSE = 1.5218, Val RMSE = 14.0759, Time = 227.2s\n",
      "2025-12-07 15:25:35,204 - INFO - (PID 24332) - Round 13: Train RMSE = 1.5126, Val RMSE = 13.7527, Time = 226.5s\n",
      "2025-12-07 15:29:28,091 - INFO - (PID 24332) - Round 14: Train RMSE = 1.5305, Val RMSE = 14.5117, Time = 232.9s\n",
      "2025-12-07 15:33:01,273 - INFO - (PID 24332) - Round 15: Train RMSE = 1.5029, Val RMSE = 13.5764, Time = 213.2s\n",
      "2025-12-07 15:36:19,897 - INFO - (PID 24332) - Round 16: Train RMSE = 1.5034, Val RMSE = 13.3902, Time = 198.6s\n",
      "2025-12-07 15:41:40,281 - INFO - (PID 24332) - Round 17: Train RMSE = 1.5145, Val RMSE = 15.8894, Time = 320.4s\n",
      "2025-12-07 15:45:59,182 - INFO - (PID 24332) - Round 18: Train RMSE = 1.5108, Val RMSE = 14.9188, Time = 258.9s\n",
      "2025-12-07 15:50:06,449 - INFO - (PID 24332) - Round 19: Train RMSE = 1.4968, Val RMSE = 14.3775, Time = 247.3s\n",
      "2025-12-07 15:54:11,042 - INFO - (PID 24332) - Round 20: Train RMSE = 1.5050, Val RMSE = 14.0293, Time = 244.6s\n",
      "2025-12-07 15:58:18,118 - INFO - (PID 24332) - Round 21: Train RMSE = 1.4945, Val RMSE = 16.0919, Time = 247.1s\n",
      "2025-12-07 16:02:13,684 - INFO - (PID 24332) - Round 22: Train RMSE = 1.4736, Val RMSE = 13.5866, Time = 235.6s\n",
      "2025-12-07 16:06:11,596 - INFO - (PID 24332) - Round 23: Train RMSE = 1.4751, Val RMSE = 13.1295, Time = 237.9s\n",
      "2025-12-07 16:10:04,156 - INFO - (PID 24332) - Round 24: Train RMSE = 1.4701, Val RMSE = 13.2224, Time = 232.6s\n",
      "2025-12-07 16:14:00,684 - INFO - (PID 24332) - Round 25: Train RMSE = 1.4761, Val RMSE = 13.4350, Time = 236.5s\n",
      "2025-12-07 16:18:08,927 - INFO - (PID 24332) - Round 26: Train RMSE = 1.5085, Val RMSE = 13.5084, Time = 248.2s\n",
      "2025-12-07 16:22:05,706 - INFO - (PID 24332) - Round 27: Train RMSE = 1.4513, Val RMSE = 13.0287, Time = 236.8s\n",
      "2025-12-07 16:26:00,265 - INFO - (PID 24332) - Round 28: Train RMSE = 1.4411, Val RMSE = 12.4879, Time = 234.6s\n",
      "2025-12-07 16:30:38,663 - INFO - (PID 24332) - Round 29: Train RMSE = 1.4532, Val RMSE = 15.9505, Time = 278.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 16:36:58,921 - INFO - (PID 24332) - Round 30: Train RMSE = 1.4629, Val RMSE = 15.2283, Time = 380.3s\n",
      "2025-12-07 16:43:23,586 - INFO - (PID 24332) - Round 31: Train RMSE = 1.4657, Val RMSE = 16.8618, Time = 384.7s\n",
      "2025-12-07 16:49:24,222 - INFO - (PID 24332) - Round 32: Train RMSE = 1.4340, Val RMSE = 14.5117, Time = 360.6s\n",
      "2025-12-07 16:53:24,215 - INFO - (PID 24332) - Round 33: Train RMSE = 1.4287, Val RMSE = 12.8875, Time = 240.0s\n",
      "2025-12-07 17:03:02,230 - INFO - (PID 24332) - Round 34: Train RMSE = 1.4378, Val RMSE = 13.8992, Time = 578.0s\n",
      "2025-12-07 17:09:44,762 - INFO - (PID 24332) - Round 35: Train RMSE = 1.4468, Val RMSE = 13.8802, Time = 402.5s\n",
      "2025-12-07 17:14:47,312 - INFO - (PID 24332) - Round 36: Train RMSE = 1.4465, Val RMSE = 13.7690, Time = 302.5s\n",
      "2025-12-07 17:21:26,567 - INFO - (PID 24332) - Round 37: Train RMSE = 1.4398, Val RMSE = 15.0974, Time = 399.3s\n",
      "2025-12-07 17:28:40,894 - INFO - (PID 24332) - Round 38: Train RMSE = 1.4170, Val RMSE = 12.7382, Time = 434.3s\n",
      "2025-12-07 17:35:46,538 - INFO - (PID 24332) - Round 39: Train RMSE = 1.4517, Val RMSE = 14.3428, Time = 425.6s\n",
      "2025-12-07 17:42:47,135 - INFO - (PID 24332) - Round 40: Train RMSE = 1.4591, Val RMSE = 15.1963, Time = 420.6s\n",
      "2025-12-07 17:49:57,829 - INFO - (PID 24332) - Round 41: Train RMSE = 1.4681, Val RMSE = 13.3454, Time = 430.7s\n",
      "2025-12-07 17:56:45,411 - INFO - (PID 24332) - Round 42: Train RMSE = 1.4602, Val RMSE = 18.5857, Time = 407.6s\n",
      "2025-12-07 18:03:34,120 - INFO - (PID 24332) - Round 43: Train RMSE = 1.4505, Val RMSE = 15.2057, Time = 408.7s\n",
      "2025-12-07 18:03:34,123 - INFO - (PID 24332) - Federated training stopped early at round 43.\n",
      "2025-12-07 18:03:34,168 - INFO - (PID 24332) - Federated BiLSTM-AE completed. RMSE: 12.4879\n",
      "2025-12-07 18:03:34,176 - INFO - (PID 24332) - --- Training Transformer-AE ---\n",
      "2025-12-07 18:03:51,723 - INFO - (PID 24332) -     Starting Centralized training for Transformer-AE...\n",
      "2025-12-07 18:16:23,611 - INFO - (PID 24332) - Centralized Transformer-AE completed. RMSE: 12.1445\n",
      "2025-12-07 18:16:23,919 - INFO - (PID 24332) - Starting optimized federated training for Transformer-AE...\n",
      "2025-12-07 18:18:38,801 - INFO - (PID 24332) - Round 1: Train RMSE = 1.9584, Val RMSE = 23.4943, Time = 134.9s\n",
      "2025-12-07 18:20:48,570 - INFO - (PID 24332) - Round 2: Train RMSE = 1.8893, Val RMSE = 21.5654, Time = 129.8s\n",
      "2025-12-07 18:22:58,571 - INFO - (PID 24332) - Round 3: Train RMSE = 1.8399, Val RMSE = 20.4137, Time = 130.0s\n",
      "2025-12-07 18:25:06,301 - INFO - (PID 24332) - Round 4: Train RMSE = 1.8301, Val RMSE = 20.5858, Time = 127.7s\n",
      "2025-12-07 18:27:15,432 - INFO - (PID 24332) - Round 5: Train RMSE = 1.8091, Val RMSE = 18.9957, Time = 129.1s\n",
      "2025-12-07 18:29:26,952 - INFO - (PID 24332) - Round 6: Train RMSE = 1.7785, Val RMSE = 18.9537, Time = 131.5s\n",
      "2025-12-07 18:31:33,634 - INFO - (PID 24332) - Round 7: Train RMSE = 1.7691, Val RMSE = 18.9519, Time = 126.7s\n",
      "2025-12-07 18:33:38,848 - INFO - (PID 24332) - Round 8: Train RMSE = 1.7282, Val RMSE = 18.3663, Time = 125.2s\n",
      "2025-12-07 18:35:46,552 - INFO - (PID 24332) - Round 9: Train RMSE = 1.7105, Val RMSE = 18.3498, Time = 127.7s\n",
      "2025-12-07 18:37:52,497 - INFO - (PID 24332) - Round 10: Train RMSE = 1.6730, Val RMSE = 17.9186, Time = 125.9s\n",
      "2025-12-07 18:39:58,331 - INFO - (PID 24332) - Round 11: Train RMSE = 1.6576, Val RMSE = 17.8678, Time = 125.8s\n",
      "2025-12-07 18:42:02,820 - INFO - (PID 24332) - Round 12: Train RMSE = 1.6542, Val RMSE = 17.7746, Time = 124.5s\n",
      "2025-12-07 18:44:08,800 - INFO - (PID 24332) - Round 13: Train RMSE = 1.6351, Val RMSE = 17.6514, Time = 126.0s\n",
      "2025-12-07 18:46:24,333 - INFO - (PID 24332) - Round 14: Train RMSE = 1.6265, Val RMSE = 16.8648, Time = 135.5s\n",
      "2025-12-07 18:48:30,082 - INFO - (PID 24332) - Round 15: Train RMSE = 1.6209, Val RMSE = 16.8962, Time = 125.7s\n",
      "2025-12-07 18:50:39,273 - INFO - (PID 24332) - Round 16: Train RMSE = 1.6096, Val RMSE = 17.2709, Time = 129.2s\n",
      "2025-12-07 18:52:43,032 - INFO - (PID 24332) - Round 17: Train RMSE = 1.6040, Val RMSE = 17.1333, Time = 123.8s\n",
      "2025-12-07 18:54:47,452 - INFO - (PID 24332) - Round 18: Train RMSE = 1.5956, Val RMSE = 16.4122, Time = 124.4s\n",
      "2025-12-07 18:56:53,396 - INFO - (PID 24332) - Round 19: Train RMSE = 1.5831, Val RMSE = 16.0779, Time = 125.9s\n",
      "2025-12-07 18:58:59,078 - INFO - (PID 24332) - Round 20: Train RMSE = 1.5852, Val RMSE = 16.5920, Time = 125.7s\n",
      "2025-12-07 19:01:04,760 - INFO - (PID 24332) - Round 21: Train RMSE = 1.5834, Val RMSE = 15.9478, Time = 125.7s\n",
      "2025-12-07 19:03:09,104 - INFO - (PID 24332) - Round 22: Train RMSE = 1.5805, Val RMSE = 16.2998, Time = 124.3s\n",
      "2025-12-07 19:05:16,976 - INFO - (PID 24332) - Round 23: Train RMSE = 1.5798, Val RMSE = 16.0350, Time = 127.9s\n",
      "2025-12-07 19:07:21,362 - INFO - (PID 24332) - Round 24: Train RMSE = 1.5992, Val RMSE = 17.2259, Time = 124.4s\n",
      "2025-12-07 19:09:25,837 - INFO - (PID 24332) - Round 25: Train RMSE = 1.5931, Val RMSE = 16.0464, Time = 124.5s\n",
      "2025-12-07 19:11:30,938 - INFO - (PID 24332) - Round 26: Train RMSE = 1.5906, Val RMSE = 15.9917, Time = 125.1s\n",
      "2025-12-07 19:13:36,526 - INFO - (PID 24332) - Round 27: Train RMSE = 1.5942, Val RMSE = 16.0766, Time = 125.6s\n",
      "2025-12-07 19:15:43,213 - INFO - (PID 24332) - Round 28: Train RMSE = 1.5803, Val RMSE = 15.2516, Time = 126.7s\n",
      "2025-12-07 19:17:48,363 - INFO - (PID 24332) - Round 29: Train RMSE = 1.5877, Val RMSE = 15.4725, Time = 125.1s\n",
      "2025-12-07 19:19:57,600 - INFO - (PID 24332) - Round 30: Train RMSE = 1.5784, Val RMSE = 14.9316, Time = 129.2s\n",
      "2025-12-07 19:22:01,525 - INFO - (PID 24332) - Round 31: Train RMSE = 1.5851, Val RMSE = 16.0677, Time = 123.9s\n",
      "2025-12-07 19:24:05,471 - INFO - (PID 24332) - Round 32: Train RMSE = 1.5788, Val RMSE = 15.1418, Time = 123.9s\n",
      "2025-12-07 19:26:09,633 - INFO - (PID 24332) - Round 33: Train RMSE = 1.5717, Val RMSE = 14.4747, Time = 124.2s\n",
      "2025-12-07 19:28:13,596 - INFO - (PID 24332) - Round 34: Train RMSE = 1.5816, Val RMSE = 15.9553, Time = 124.0s\n",
      "2025-12-07 19:30:19,242 - INFO - (PID 24332) - Round 35: Train RMSE = 1.5870, Val RMSE = 15.6181, Time = 125.6s\n",
      "2025-12-07 19:32:30,731 - INFO - (PID 24332) - Round 36: Train RMSE = 1.5609, Val RMSE = 13.8784, Time = 131.5s\n",
      "2025-12-07 19:34:39,940 - INFO - (PID 24332) - Round 37: Train RMSE = 1.5876, Val RMSE = 15.1484, Time = 129.2s\n",
      "2025-12-07 19:36:50,779 - INFO - (PID 24332) - Round 38: Train RMSE = 1.5657, Val RMSE = 15.2360, Time = 130.8s\n",
      "2025-12-07 19:39:02,322 - INFO - (PID 24332) - Round 39: Train RMSE = 1.5845, Val RMSE = 15.4440, Time = 131.5s\n",
      "2025-12-07 19:41:12,233 - INFO - (PID 24332) - Round 40: Train RMSE = 1.5717, Val RMSE = 15.3301, Time = 129.9s\n",
      "2025-12-07 19:43:25,897 - INFO - (PID 24332) - Round 41: Train RMSE = 1.5865, Val RMSE = 15.1829, Time = 133.7s\n",
      "2025-12-07 19:45:34,012 - INFO - (PID 24332) - Round 42: Train RMSE = 1.5981, Val RMSE = 15.9528, Time = 128.1s\n",
      "2025-12-07 19:47:44,241 - INFO - (PID 24332) - Round 43: Train RMSE = 1.5934, Val RMSE = 18.0500, Time = 130.2s\n",
      "2025-12-07 19:49:52,535 - INFO - (PID 24332) - Round 44: Train RMSE = 1.5928, Val RMSE = 15.5438, Time = 128.3s\n",
      "2025-12-07 19:52:07,716 - INFO - (PID 24332) - Round 45: Train RMSE = 1.5751, Val RMSE = 15.3233, Time = 135.2s\n",
      "2025-12-07 19:54:17,856 - INFO - (PID 24332) - Round 46: Train RMSE = 1.6303, Val RMSE = 23.2930, Time = 130.1s\n",
      "2025-12-07 19:56:30,419 - INFO - (PID 24332) - Round 47: Train RMSE = 1.5990, Val RMSE = 16.2295, Time = 132.5s\n",
      "2025-12-07 19:58:41,340 - INFO - (PID 24332) - Round 48: Train RMSE = 1.5961, Val RMSE = 15.8196, Time = 130.9s\n",
      "2025-12-07 20:00:48,016 - INFO - (PID 24332) - Round 49: Train RMSE = 1.5883, Val RMSE = 15.0109, Time = 126.7s\n",
      "2025-12-07 20:02:56,847 - INFO - (PID 24332) - Round 50: Train RMSE = 1.5874, Val RMSE = 15.8945, Time = 128.8s\n",
      "2025-12-07 20:02:56,860 - INFO - (PID 24332) - Federated Transformer-AE completed. RMSE: 13.8784\n",
      "2025-12-07 20:02:56,888 - INFO - (PID 24332) - OPTIMIZED multi-model pipeline completed! Results saved to: optimized_fhir_research\\multi_model_20251207T130853\n",
      "2025-12-07 20:02:57,521 - INFO - (PID 24332) - Graph 1/5: Convergence plot saved.\n",
      "2025-12-07 20:02:58,073 - INFO - (PID 24332) - Graph 2/5: Multi-model RMSE comparison plot saved.\n",
      "2025-12-07 20:02:58,587 - INFO - (PID 24332) - Graph 3/5: Performance ratio plot saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 20:03:01,499 - INFO - (PID 24332) - Graph 5/5: Residual error distribution plot saved.\n",
      "2025-12-07 20:03:01,899 - INFO - (PID 24332) - Graph 4/5: Sequence reconstruction plot saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPTIMIZED PIPELINE - MULTI-MODEL RESULTS SUMMARY (Utility Focus)\n",
      "================================================================================\n",
      "MODEL PERFORMANCE (UNSCALED METRICS):\n",
      "| Model          |   Cent. RMSE |   FL RMSE |   Cent. MAE |   FL MAE | Ratio (FL/Cent)   |\n",
      "|:---------------|-------------:|----------:|------------:|---------:|:------------------|\n",
      "| BiLSTM-AE      |       9.6116 |   12.4879 |      3.9608 |   6.3463 | 1.30x             |\n",
      "| Conv1D-AE      |      10.9287 |   13.5895 |      6.2585 |   7.4671 | 1.24x             |\n",
      "| Transformer-AE |      12.1445 |   13.8784 |      5.6359 |   7.2113 | 1.14x             |\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DIFFERENTIAL PRIVACY & FEATURE SUMMARY:\n",
      "  Total Privacy Budget: ($\\epsilon$=58.9307, $\\delta$=1e-05)\n",
      "  Noise Multiplier ($\\sigma$): 1.0\n",
      "  Assessment: MODERATE Privacy Guarantee\n",
      "\n",
      "DATA STATISTICS:\n",
      "  Total Observations: 47820\n",
      "  Sequences (Approximate): 36503\n",
      "  Input Shape (Sequence Length, Total Features): (3, 14)\n",
      "  Continuous Features (10): Heart Rate, Respiratory Rate, O2 Saturation, Systolic BP, Diastolic BP, Mean Arterial Pressure, Temperature, Glucose, Creatinine, Urea Nitrogen\n",
      "  Categorical Features (4): Gender_f, Gender_m, Age_Adult, Age_Senior\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "OPTIMIZED FHIR RESEARCH PIPELINE (V12: FINAL Utility Improvement Fix)\n",
    "- Maintains architectural simplification (Fix 6).\n",
    "- **CRITICAL FIX 7:** Reduced DP Noise Multiplier (sigma) from 1.5 to 1.0 to significantly improve model utility (lower RMSEs).\n",
    "- Adds two new publication-quality plots.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "import glob \n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set backend to avoid display issues\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# ---------------------------\n",
    "# GLOBAL DATA CONFIGURATION \n",
    "# ---------------------------\n",
    "# NOTE: Ensure this directory path is correct on your system\n",
    "FHIR_INPUT_DIR = r\"C:\\mimic-iv-2.2\\mimic_fhir_5000_output\" \n",
    "TOTAL_FILES_TO_PROCESS = 5000 \n",
    "\n",
    "CONTINUOUS_FEATURES = [\n",
    "    'Heart Rate', 'Respiratory Rate', 'O2 Saturation', \n",
    "    'Systolic BP', 'Diastolic BP', 'Mean Arterial Pressure',\n",
    "    'Temperature', 'Glucose', 'Creatinine', 'Urea Nitrogen'\n",
    "]\n",
    "CATEGORICAL_FEATURES = [] # Placeholder to be populated after one-hot encoding\n",
    "\n",
    "# CRITICAL FIX & ENHANCEMENT: Mapping of MIMIC-IV ItemIDs to feature names\n",
    "VITAL_SIGN_ITEM_ID_MAP = {\n",
    "    # Vitals\n",
    "    '220045': 'Heart Rate', '211': 'Heart Rate', \n",
    "    '220210': 'Respiratory Rate', '618': 'Respiratory Rate', '224690': 'Respiratory Rate',\n",
    "    '220277': 'O2 Saturation', '646': 'O2 Saturation', '223769': 'O2 Saturation',\n",
    "    '220050': 'Systolic BP', '51': 'Systolic BP', '455': 'Systolic BP',\n",
    "    '220051': 'Diastolic BP', '8368': 'Diastolic BP', '456': 'Diastolic BP',\n",
    "    '220052': 'Mean Arterial Pressure', '52': 'Mean Arterial Pressure', '457': 'Mean Arterial Pressure',\n",
    "    '223761': 'Temperature', '678': 'Temperature', \n",
    "    # Labs (Common ItemIDs)\n",
    "    '50931': 'Glucose', '50809': 'Glucose',\n",
    "    '50912': 'Creatinine',\n",
    "    '51006': 'Urea Nitrogen',\n",
    "}\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# OPTIMIZED Configuration (CRITICAL FIX FOR UTILITY - FIX 7)\n",
    "# ---------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "OPTIMIZED_CONFIG = {\n",
    "    \"SEEDS\": [42],\n",
    "    \"GLOBAL_ROUNDS\": 50,  # Increased for better convergence\n",
    "    \"LOCAL_EPOCHS\": 5,    \n",
    "    \"CENTRALIZED_LR\": 5e-4, \n",
    "    \"FEDERATED_LR\": 5e-5,   # *** TWEAKED: Lowered from 1e-4 to 5e-5 to stabilize DP training ***\n",
    "    \"PATIENCE\": 15,       \n",
    "    \"MIN_DELTA\": 1e-4,\n",
    "    \"SEQUENCE_LENGTH\": 3, \n",
    "    # Differential Privacy (DP) Parameters (CRITICAL ADJUSTMENT FOR UTILITY - FIX 7)\n",
    "    \"DP_CLIP_NORM\": 1.0, \n",
    "    \"DP_SIGMA\": 1.0,     # *** CRITICAL CHANGE: Reduced from 1.5 to 1.0 for better RMSEs (utility) ***\n",
    "    \"DELTA\": 1e-5,       \n",
    "    \"SAMPLING_Q\": 1.0, \n",
    "    \"NUM_CLIENTS\": 3\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# DP Epsilon Calculation \n",
    "# ---------------------------\n",
    "\n",
    "def calculate_dp_epsilon(sigma, q, T, delta):\n",
    "    \"\"\"Calculates the total privacy budget (epsilon) using RDP.\"\"\"\n",
    "    if sigma <= 0.0 or T <= 0: return None, float('inf')\n",
    "    q = max(min(q, 1.0), 1e-9) \n",
    "\n",
    "    def rdp_gaussian(alpha):\n",
    "        if alpha <= 1.0: return 0.0\n",
    "        sigma_sq = sigma**2\n",
    "        if q == 1.0:\n",
    "            return alpha / (2 * sigma_sq)\n",
    "        else:\n",
    "            exponent = alpha * (alpha - 1) / (2 * sigma_sq)\n",
    "            log_term = np.log( (1 - q) + q * np.exp(exponent) ) \n",
    "            return log_term / (alpha - 1)\n",
    "\n",
    "    def total_rdp(alpha): return T * rdp_gaussian(alpha)\n",
    "\n",
    "    def get_epsilon(alpha):\n",
    "        if alpha <= 1.0: return float('inf')\n",
    "        rho = total_rdp(alpha)\n",
    "        return rho + np.log(1 / delta) / (alpha - 1) \n",
    "\n",
    "    res = minimize_scalar(get_epsilon, bounds=(1.01, 200), method='bounded', options={'maxiter': 500})\n",
    "    \n",
    "    if res.success and res.fun < 1000: return res.x, res.fun\n",
    "    else:\n",
    "        return None, float('inf')\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 1: DATA LOADING (Unchanged)\n",
    "# ---------------------------\n",
    "\n",
    "def load_fhir_data(num_files_target=TOTAL_FILES_TO_PROCESS):\n",
    "    \"\"\"Loads real patient time series and demographic data by parsing FHIR JSON files.\"\"\"    \n",
    "    logging.info(f\"Processing up to {num_files_target} FHIR files from directory: {FHIR_INPUT_DIR}\")\n",
    "    \n",
    "    all_json_files = sorted(glob.glob(os.path.join(FHIR_INPUT_DIR, \"patient_*.json\")))\n",
    "    files_to_process = all_json_files[:num_files_target]\n",
    "    \n",
    "    if not files_to_process:\n",
    "        logging.error(f\"FATAL: No patient JSON files found in {FHIR_INPUT_DIR}. Please check the path.\")\n",
    "        raise FileNotFoundError(f\"No JSON files found at {FHIR_INPUT_DIR}\")\n",
    "\n",
    "    patient_data_list = []\n",
    "    \n",
    "    for i, file_path in enumerate(files_to_process):\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                bundle = json.load(f)\n",
    "            \n",
    "            patient_id = Path(file_path).stem.replace(\"patient_\", \"\")\n",
    "            temp_data = defaultdict(lambda: {})\n",
    "            demographics = {'subject_id': patient_id}\n",
    "            \n",
    "            for entry in bundle.get('entry', []):\n",
    "                resource = entry.get('resource', {})\n",
    "                resource_type = resource.get('resourceType')\n",
    "\n",
    "                if resource_type == 'Patient':\n",
    "                    demographics['Gender'] = resource.get('gender', 'unknown')\n",
    "                    for ext in resource.get('extension', []):\n",
    "                        if ext.get('url').endswith('deid-anchor-age'):\n",
    "                            demographics['Age'] = ext.get('valueInteger')\n",
    "                            break\n",
    "                    \n",
    "                    if 'Age' in demographics:\n",
    "                         if demographics['Age'] < 18: demographics['Age_Group'] = 'Child'\n",
    "                         elif demographics['Age'] < 65: demographics['Age_Group'] = 'Adult'\n",
    "                         else: demographics['Age_Group'] = 'Senior'\n",
    "                    else:\n",
    "                        demographics['Age_Group'] = 'unknown_age'\n",
    "                    \n",
    "                elif resource_type == 'Observation':\n",
    "                    \n",
    "                    offset_days = None\n",
    "                    for ext in resource.get('extension', []):\n",
    "                        if ext.get('url') == 'http://your-research.org/fhir/StructureDefinition/event-offset-days':\n",
    "                            offset_days = ext.get('valueInteger')\n",
    "                            break\n",
    "                    if offset_days is None: continue\n",
    "                   \n",
    "                    val = resource.get('valueQuantity', {}).get('value')\n",
    "                    \n",
    "                    if val is not None:\n",
    "                        code_text = resource.get('code', {}).get('text', '')\n",
    "                        if code_text in VITAL_SIGN_ITEM_ID_MAP:\n",
    "                            found_feature = VITAL_SIGN_ITEM_ID_MAP[code_text]\n",
    "                            if found_feature in CONTINUOUS_FEATURES:\n",
    "                                temp_data[found_feature][offset_days] = val\n",
    "                            \n",
    "                    components = resource.get('component', [])\n",
    "                    if components:\n",
    "                        for component in components:\n",
    "                            comp_val = component.get('valueQuantity', {}).get('value')\n",
    "                            if comp_val is not None:\n",
    "                                comp_code_text = component.get('code', {}).get('text', '')\n",
    "                                \n",
    "                                if comp_code_text in VITAL_SIGN_ITEM_ID_MAP:\n",
    "                                    found_feature = VITAL_SIGN_ITEM_ID_MAP[comp_code_text]\n",
    "                                    if found_feature in CONTINUOUS_FEATURES:\n",
    "                                        temp_data[found_feature][offset_days] = comp_val\n",
    "\n",
    "            if temp_data:\n",
    "                df = pd.DataFrame.from_dict(temp_data, orient='index').transpose()\n",
    "                df = df.sort_index().rename_axis('timestamp_offset_days')\n",
    "                df['subject_id'] = patient_id\n",
    "                \n",
    "                for k, v in demographics.items():\n",
    "                    if k != 'subject_id' and k in ['Gender', 'Age_Group']:\n",
    "                        df[k] = v\n",
    "                \n",
    "                present_continuous_features = [f for f in CONTINUOUS_FEATURES if f in df.columns]\n",
    "                \n",
    "                if present_continuous_features and not df[present_continuous_features].dropna(how='all').empty:\n",
    "                    patient_data_list.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not patient_data_list:\n",
    "        raise ValueError(\"Cannot proceed without real data from JSON files.\")\n",
    "\n",
    "    combined_data = pd.concat(patient_data_list, ignore_index=False)\n",
    "    combined_data = combined_data.reset_index().rename(columns={'index': 'timestamp_offset_days'})\n",
    "    \n",
    "    # Impute missing continuous features\n",
    "    final_continuous_features = [f for f in CONTINUOUS_FEATURES if f in combined_data.columns]\n",
    "    \n",
    "    if final_continuous_features:\n",
    "        combined_data[final_continuous_features] = combined_data.groupby('subject_id')[final_continuous_features].ffill().bfill()\n",
    "        combined_data.dropna(subset=final_continuous_features, how='all', inplace=True)\n",
    "    \n",
    "    # Handle Categorical Features (One-Hot Encoding)\n",
    "    for feature in ['Gender', 'Age_Group']:\n",
    "        if feature in combined_data.columns:\n",
    "            combined_data[feature] = combined_data[feature].fillna(combined_data[feature].mode()[0] if not combined_data[feature].mode().empty else 'unknown_default')\n",
    "    \n",
    "    if 'Gender' in combined_data.columns and 'Age_Group' in combined_data.columns:\n",
    "        combined_data = pd.get_dummies(combined_data, columns=['Gender', 'Age_Group'], prefix=['Gender', 'Age'])\n",
    "        global CATEGORICAL_FEATURES\n",
    "        # Filter OHE columns to match the features used in the log\n",
    "        CATEGORICAL_FEATURES = [col for col in combined_data.columns if col in ['Gender_f', 'Gender_m', 'Age_Adult', 'Age_Senior']]\n",
    "    else:\n",
    "        CATEGORICAL_FEATURES = []\n",
    "        \n",
    "    logging.info(f\"Successfully loaded and combined data from {len(combined_data['subject_id'].unique())} unique patients.\")\n",
    "    \n",
    "    data_stats = {\n",
    "        'total_observations': len(combined_data),\n",
    "        'continuous_features': final_continuous_features,\n",
    "        'categorical_features': CATEGORICAL_FEATURES,\n",
    "    }\n",
    "    \n",
    "    return combined_data, data_stats\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 2: DATA PREPROCESSING (Unchanged)\n",
    "# ---------------------------\n",
    "\n",
    "def preprocess_data(data_df, config):\n",
    "    \"\"\"Transforms the combined patient data into time-series sequences.\"\"\"\n",
    "    selected_features = CONTINUOUS_FEATURES + CATEGORICAL_FEATURES\n",
    "    final_features = [f for f in selected_features if f in data_df.columns]\n",
    "    \n",
    "    rows_before = len(data_df)\n",
    "    data_df.dropna(subset=final_features, inplace=True)\n",
    "    rows_after = len(data_df)\n",
    "    if rows_before != rows_after:\n",
    "        logging.warning(f\"Removed {rows_before - rows_after} rows containing final NaNs before sequence creation.\")\n",
    "    if data_df.empty:\n",
    "        raise ValueError(\"Preprocessing failed: No data remaining after final NaN removal.\")\n",
    "    \n",
    "    subject_ids = data_df['subject_id'].unique()\n",
    "    num_patients = len(subject_ids)\n",
    "    \n",
    "    if num_patients == 0 or not final_features:\n",
    "        raise ValueError(\"Preprocessing failed: No patients or no features remaining after cleanup.\")\n",
    "\n",
    "    np.random.seed(config['SEEDS'][0])\n",
    "    np.random.shuffle(subject_ids)\n",
    "    \n",
    "    # Split 70/15/15 for Train/Validation/Test (or 70/30 Train/Val-Test here)\n",
    "    train_split = int(0.7 * num_patients)\n",
    "    val_split = int(0.15 * num_patients) # Using 15% for validation as per common practice\n",
    "    \n",
    "    train_subjects = subject_ids[:train_split]\n",
    "    val_subjects = subject_ids[train_split:train_split + val_split]\n",
    "\n",
    "    continuous_features_only = [f for f in final_features if f in CONTINUOUS_FEATURES]\n",
    "    scaler = RobustScaler()\n",
    "    train_data_for_scaler = data_df[data_df['subject_id'].isin(train_subjects)][continuous_features_only].values\n",
    "    \n",
    "    if train_data_for_scaler.size == 0:\n",
    "        raise ValueError(\"No training data to fit continuous feature scaler.\")\n",
    "        \n",
    "    scaler.fit(train_data_for_scaler)\n",
    "    \n",
    "    def transform_data(df, scaler):\n",
    "        df_scaled = df.copy()\n",
    "        if continuous_features_only:\n",
    "            df_scaled[continuous_features_only] = scaler.transform(df[continuous_features_only].values)\n",
    "        return df_scaled[final_features].values\n",
    "\n",
    "    def create_sequences(subjects, data_source, scaler):\n",
    "        sequences = []\n",
    "        sequence_length = config['SEQUENCE_LENGTH']\n",
    "        for subj_id in subjects:\n",
    "            patient_data = data_source[data_source['subject_id'] == subj_id]\n",
    "            scaled_patient_data = transform_data(patient_data, scaler) \n",
    "            \n",
    "            if len(scaled_patient_data) < sequence_length:\n",
    "                 continue \n",
    "            \n",
    "            for i in range(len(scaled_patient_data) - sequence_length + 1):\n",
    "                sequences.append(scaled_patient_data[i:i + sequence_length])\n",
    "        \n",
    "        return np.array(sequences, dtype=np.float32) \n",
    "\n",
    "    X_val = create_sequences(val_subjects, data_df, scaler)\n",
    "    # Store patient data for plotting later (optional, but helpful)\n",
    "    val_patient_data = data_df[data_df['subject_id'].isin(val_subjects)].reset_index(drop=True)\n",
    "\n",
    "    num_clients = config['NUM_CLIENTS']\n",
    "    client_train_subjects = np.array_split(train_subjects, num_clients)\n",
    "    \n",
    "    client_datasets = []\n",
    "    for client_subjects in client_train_subjects:\n",
    "        client_data = create_sequences(client_subjects, data_df, scaler)\n",
    "        if client_data.size > 0:\n",
    "            client_datasets.append(client_data)\n",
    "    \n",
    "    if not client_datasets:\n",
    "        raise ValueError(\"No training sequences generated for centralized model.\")\n",
    "        \n",
    "    X_train = np.concatenate(client_datasets).astype(np.float32) \n",
    "    \n",
    "    total_sequences = len(X_train) + len(X_val)\n",
    "    \n",
    "    logging.info(f\"Total training sequences generated: {len(X_train)}\")\n",
    "    logging.info(f\"Total validation sequences generated: {len(X_val)}\")\n",
    "    \n",
    "    metadata = {\n",
    "        'feature_names': final_features,\n",
    "        'continuous_feature_count': len(continuous_features_only),\n",
    "        'categorical_feature_count': len(CATEGORICAL_FEATURES),\n",
    "        'total_sequences': total_sequences, \n",
    "        'input_shape': X_train.shape[1:],\n",
    "        'client_shapes': [d.shape for d in client_datasets]\n",
    "    }\n",
    "    \n",
    "    return X_train, X_val, client_datasets, scaler, metadata, val_patient_data\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 3: MODEL ARCHITECTURES (Fix 6 Maintained)\n",
    "# ---------------------------\n",
    "\n",
    "# Autoencoder functions remain the same as the last version (Conv1D-AE, BiLSTM-AE, Transformer-AE)\n",
    "# to maintain stability and prevent the MemoryError seen in earlier runs.\n",
    "\n",
    "def create_conv1d_autoencoder(input_shape):\n",
    "    \"\"\"Conv1D Autoencoder (Stable Baseline with Strong L2)\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    L2_REG = 1e-4\n",
    "    x = layers.Conv1D(filters=64, kernel_size=1, activation='relu', padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(L2_REG))(inputs) \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    bottleneck_size = input_shape[0] * input_shape[1] // 2 \n",
    "    x = layers.Flatten()(x)\n",
    "    bottleneck = layers.Dense(bottleneck_size, activation='relu', \n",
    "                              activity_regularizer=regularizers.l2(L2_REG))(x)\n",
    "    x = layers.Dense(input_shape[0] * input_shape[1], activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(L2_REG))(bottleneck) \n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Reshape(input_shape)(x)\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"Conv1D-AE\")\n",
    "\n",
    "def create_bilstm_autoencoder(input_shape):\n",
    "    \"\"\"Bidirectional LSTM Autoencoder (EXTREME CAPACITY REDUCTION - FIX 6)\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    L2_REG = 5e-4 \n",
    "    \n",
    "    # Encoder \n",
    "    encoded = layers.Bidirectional(layers.LSTM(16, activation='tanh', return_sequences=True, \n",
    "                                               dropout=0.1, recurrent_dropout=0.1, \n",
    "                                               kernel_regularizer=regularizers.l2(L2_REG)))(inputs) \n",
    "    encoded = layers.Bidirectional(layers.LSTM(8, activation='tanh', return_sequences=False, \n",
    "                                               dropout=0.1, recurrent_dropout=0.1, \n",
    "                                               kernel_regularizer=regularizers.l2(L2_REG)))(encoded)\n",
    "    \n",
    "    # Decoder \n",
    "    decoded = layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = layers.Bidirectional(layers.LSTM(8, activation='tanh', return_sequences=True, \n",
    "                                               dropout=0.1, recurrent_dropout=0.1, \n",
    "                                               kernel_regularizer=regularizers.l2(L2_REG)))(decoded)\n",
    "    decoded = layers.Bidirectional(layers.LSTM(16, activation='tanh', return_sequences=True, \n",
    "                                               dropout=0.1, recurrent_dropout=0.1, \n",
    "                                               kernel_regularizer=regularizers.l2(L2_REG)))(decoded)\n",
    "    \n",
    "    outputs = layers.TimeDistributed(layers.Dense(input_shape[1], activation='linear'))(decoded)\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"BiLSTM-AE\")\n",
    "\n",
    "def create_transformer_autoencoder(input_shape):\n",
    "    \"\"\"Transformer Autoencoder (EXTREME SIMPLIFICATION - FIX 6)\"\"\"\n",
    "    \n",
    "    L2_REG = 1e-4 \n",
    "    \n",
    "    def transformer_block(input_tensor, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=L2_REG): \n",
    "        # Multi-Head Self Attention\n",
    "        norm_x = layers.LayerNormalization(epsilon=1e-6)(input_tensor)\n",
    "        attn_output = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(norm_x, norm_x)\n",
    "        x = layers.Add()([attn_output, input_tensor])\n",
    "        \n",
    "        # Feed Forward with L2 Regularization \n",
    "        norm_x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        ffn_output = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\", kernel_regularizer=regularizers.l2(l2_reg))(norm_x)\n",
    "        ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "        ffn_output = layers.Conv1D(filters=input_shape[-1], kernel_size=1, kernel_regularizer=regularizers.l2(l2_reg))(ffn_output)\n",
    "        return layers.Add()([ffn_output, x])\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder \n",
    "    x = transformer_block(inputs, head_size=8, num_heads=2, ff_dim=16, dropout=0.1) \n",
    "    \n",
    "    # Bottleneck \n",
    "    bottleneck = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Decoder \n",
    "    decoded = layers.Dense(input_shape[0] * input_shape[1], activation='relu', kernel_regularizer=regularizers.l2(L2_REG))(bottleneck)\n",
    "    outputs = layers.Reshape(input_shape)(decoded)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"Transformer-AE\")\n",
    "\n",
    "\n",
    "MODEL_CREATORS = {\n",
    "    \"Conv1D-AE\": create_conv1d_autoencoder,\n",
    "    \"BiLSTM-AE\": create_bilstm_autoencoder,\n",
    "    \"Transformer-AE\": create_transformer_autoencoder\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Training Functions \n",
    "# ---------------------------\n",
    "\n",
    "def inverse_transform_rmse(y_true_scaled, y_pred_scaled, scaler, num_cont_feats):\n",
    "    \"\"\"Safely calculates unscaled RMSE and MAE, guarding against NaN/Inf.\"\"\"\n",
    "    y_true_cont_scaled = y_true_scaled[:, :, :num_cont_feats]\n",
    "    y_pred_cont_scaled = y_pred_scaled[:, :, :num_cont_feats]\n",
    "    \n",
    "    y_true_flat = y_true_cont_scaled.reshape(-1, num_cont_feats)\n",
    "    y_pred_cont_flat = y_pred_cont_scaled.reshape(-1, num_cont_feats)\n",
    "    \n",
    "    # CRITICAL GUARD: Check for NaNs/Infs in the predicted scaled data before inverse transform\n",
    "    if not np.all(np.isfinite(y_pred_cont_flat)):\n",
    "        logging.error(\"Prediction contains NaN/Inf before inverse transform. Model is unstable.\")\n",
    "        return float('inf'), float('inf')\n",
    "\n",
    "    # Inverse transform\n",
    "    y_true_unscaled = scaler.inverse_transform(y_true_flat)\n",
    "    y_pred_unscaled = scaler.inverse_transform(y_pred_cont_flat)\n",
    "    \n",
    "    # CRITICAL GUARD: Check again after inverse transform\n",
    "    if not np.all(np.isfinite(y_pred_unscaled)):\n",
    "        logging.error(\"Prediction contains NaN/Inf after inverse transform. Model is unstable.\")\n",
    "        return float('inf'), float('inf') \n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_unscaled, y_pred_unscaled))\n",
    "    mae = mean_absolute_error(y_true_unscaled, y_pred_unscaled)\n",
    "    return rmse, mae\n",
    "\n",
    "def train_centralized_model(X_train, X_val, input_shape, config, scaler, model_creator, all_features):\n",
    "    tf.random.set_seed(config['SEEDS'][0])\n",
    "    model = model_creator(input_shape)\n",
    "    model.compile(optimizer=Adam(config['CENTRALIZED_LR']), loss='mse', metrics=['mae']) \n",
    "    es = EarlyStopping(monitor='val_loss', patience=config['PATIENCE'], \n",
    "                       min_delta=config['MIN_DELTA'], restore_best_weights=True)\n",
    "    rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4)\n",
    "    logging.info(f\"    Starting Centralized training for {model.name}...\")\n",
    "    model.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_val, X_val), callbacks=[es, rlp], verbose=0) \n",
    "    y_pred_scaled = model.predict(X_val, verbose=0)\n",
    "    \n",
    "    continuous_features_count = len([f for f in all_features if f in CONTINUOUS_FEATURES])\n",
    "    rmse, mae = inverse_transform_rmse(X_val, y_pred_scaled, scaler, continuous_features_count)\n",
    "    \n",
    "    logging.info(f\"Centralized {model.name} completed. RMSE: {rmse:.4f}\")\n",
    "    return model, rmse, mae\n",
    "\n",
    "\n",
    "class FLCentralTrainer:\n",
    "    def __init__(self, config, input_shape, scaler, model_creator, all_features):\n",
    "        self.config = config\n",
    "        self.input_shape = input_shape\n",
    "        self.scaler = scaler\n",
    "        self.model_creator = model_creator\n",
    "        self.global_model = self.model_creator(input_shape)\n",
    "        self.global_model.compile(optimizer=Adam(config['FEDERATED_LR']), loss='mse', metrics=['mae']) \n",
    "        self.global_weights = self.global_model.get_weights()\n",
    "        self.training_history = []\n",
    "        self.all_features = all_features\n",
    "        self.continuous_features_count = len([f for f in all_features if f in CONTINUOUS_FEATURES])\n",
    "        \n",
    "    def create_client_model(self):\n",
    "        model = self.model_creator(self.input_shape)\n",
    "        model.compile(optimizer=Adam(self.config['FEDERATED_LR']), loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def client_update(self, client_data, initial_weights):\n",
    "        client_model = self.create_client_model()\n",
    "        client_model.set_weights(initial_weights)\n",
    "        X_train_client = client_data\n",
    "        batch_size = min(32, X_train_client.shape[0])\n",
    "        client_model.fit(X_train_client, X_train_client, epochs=self.config['LOCAL_EPOCHS'], batch_size=batch_size, verbose=0)\n",
    "        client_weights = client_model.get_weights()\n",
    "        \n",
    "        # Manual Differential Privacy (DP-SGD Simulation)\n",
    "        noisy_weights = []\n",
    "        for initial_w, client_w in zip(initial_weights, client_weights):\n",
    "            update = client_w - initial_w\n",
    "            # Clipping \n",
    "            clip_norm = self.config['DP_CLIP_NORM']\n",
    "            l2_norm = np.linalg.norm(update.flatten())\n",
    "            if l2_norm > clip_norm:\n",
    "                update = update * clip_norm / l2_norm\n",
    "                \n",
    "            # Noise Addition (Scaled correctly by parameter count to avoid excessive noise)\n",
    "            # --- MINIMAL/PATCH FIX APPLIED HERE ---\n",
    "            # scale std dev by 1/sqrt(N) where N = number of params in 'update' to avoid huge per-weight noise\n",
    "            std_dev = (clip_norm * self.config['DP_SIGMA']) / np.sqrt(update.size)\n",
    "            noise = np.random.normal(0, std_dev, update.shape).astype(np.float32) \n",
    "            noisy_update = update + noise\n",
    "            \n",
    "            # Recalculate noisy weight\n",
    "            noisy_weights.append(initial_w + noisy_update)\n",
    "            \n",
    "        return noisy_weights, client_data.shape[0]\n",
    "\n",
    "    def aggregate_weights(self, client_weights_list, client_sizes):\n",
    "        new_weights = [np.zeros_like(w) for w in self.global_weights]\n",
    "        total_size = sum(client_sizes)\n",
    "        for client_w, size in zip(client_weights_list, client_sizes):\n",
    "            weight_factor = size / total_size\n",
    "            for i in range(len(new_weights)):\n",
    "                new_weights[i] += client_w[i] * weight_factor\n",
    "        self.global_weights = new_weights\n",
    "        self.global_model.set_weights(new_weights)\n",
    "\n",
    "    def evaluate_global_model(self, X_val):\n",
    "        loss_scaled, _ = self.global_model.evaluate(X_val, X_val, verbose=0) \n",
    "        y_pred_scaled = self.global_model.predict(X_val, verbose=0)\n",
    "        \n",
    "        rmse, mae = inverse_transform_rmse(X_val, y_pred_scaled, self.scaler, self.continuous_features_count)\n",
    "\n",
    "        if not np.isfinite(loss_scaled):\n",
    "            return float('inf'), float('inf'), float('inf')\n",
    "        \n",
    "        return np.sqrt(loss_scaled), rmse, mae\n",
    "\n",
    "    def train(self, client_datasets, X_val):\n",
    "        logging.info(f\"Starting optimized federated training for {self.global_model.name}...\")\n",
    "        \n",
    "        best_val_rmse = float('inf')\n",
    "        patience_counter = 0\n",
    "        final_rmse, final_mae = float('nan'), float('nan')\n",
    "        best_round_weights = [w.copy() for w in self.global_weights] # Store the best weights\n",
    "\n",
    "        for round_num in range(1, self.config['GLOBAL_ROUNDS'] + 1):\n",
    "            start_time = time.time()\n",
    "            num_clients = len(client_datasets)\n",
    "            num_sampled = max(1, int(num_clients * self.config['SAMPLING_Q']))\n",
    "            sampled_indices = np.random.choice(range(num_clients), num_sampled, replace=False)\n",
    "            selected_clients = [client_datasets[i] for i in sampled_indices if client_datasets[i].size > 0]\n",
    "            client_weights_list = []\n",
    "            client_sizes = []\n",
    "            \n",
    "            for client_data in selected_clients:\n",
    "                noisy_weights, size = self.client_update(client_data, self.global_weights)\n",
    "                client_weights_list.append(noisy_weights)\n",
    "                client_sizes.append(size)\n",
    "                \n",
    "            if client_weights_list:\n",
    "                self.aggregate_weights(client_weights_list, client_sizes)\n",
    "                train_rmse_scaled, val_rmse, val_mae = self.evaluate_global_model(X_val)\n",
    "            else:\n",
    "                train_rmse_scaled, val_rmse, val_mae = float('nan'), float('nan'), float('nan')\n",
    "                \n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            if np.isfinite(val_rmse) and val_rmse < 10000: \n",
    "                self.training_history.append({\n",
    "                    'model': self.global_model.name, 'round': round_num, 'train_rmse': train_rmse_scaled, 'val_rmse': val_rmse, 'val_mae': val_mae, 'time': elapsed\n",
    "                })\n",
    "                \n",
    "                logging.info(f\"Round {round_num}: Train RMSE = {train_rmse_scaled:.4f}, Val RMSE = {val_rmse:.4f}, Time = {elapsed:.1f}s\")\n",
    "                \n",
    "                if val_rmse < best_val_rmse - self.config['MIN_DELTA']:\n",
    "                    best_val_rmse = val_rmse\n",
    "                    final_rmse = val_rmse\n",
    "                    final_mae = val_mae\n",
    "                    patience_counter = 0\n",
    "                    best_round_weights = [w.copy() for w in self.global_weights]\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "            else:\n",
    "                logging.warning(f\"Round {round_num}: Model instability detected (NaN/Inf or RMSE={val_rmse:.0f}). Reverting to best weights and increasing patience.\")\n",
    "                patience_counter += 1\n",
    "                self.global_model.set_weights(best_round_weights) \n",
    "            \n",
    "            if patience_counter >= self.config['PATIENCE'] or round_num >= self.config['GLOBAL_ROUNDS']:\n",
    "                if patience_counter >= self.config['PATIENCE']:\n",
    "                    logging.info(f\"Federated training stopped early at round {round_num}.\")\n",
    "                \n",
    "                # Restore the best stable weights found\n",
    "                self.global_model.set_weights(best_round_weights)\n",
    "                \n",
    "                if not np.isfinite(final_rmse):\n",
    "                    final_rmse, final_mae = self.evaluate_global_model(X_val)[1:]\n",
    "                \n",
    "                break\n",
    "        \n",
    "        final_rmse = final_rmse if np.isfinite(final_rmse) else best_val_rmse\n",
    "        \n",
    "        logging.info(f\"Federated {self.global_model.name} completed. RMSE: {final_rmse:.4f}\")\n",
    "        return self.global_model, final_rmse, final_mae\n",
    "\n",
    "\n",
    "def plot_detailed_conv1d_performance(model, X_val, scaler, all_features, save_path):\n",
    "    \"\"\"Generates two new publication-quality plots for the Conv1D-AE model.\"\"\"\n",
    "    y_pred_scaled = model.predict(X_val, verbose=0)\n",
    "    \n",
    "    num_cont_feats = len([f for f in all_features if f in CONTINUOUS_FEATURES])\n",
    "    \n",
    "    y_true_cont_scaled = X_val[:, :, :num_cont_feats]\n",
    "    y_pred_cont_scaled = y_pred_scaled[:, :, :num_cont_feats]\n",
    "    \n",
    "    y_true_flat = y_true_cont_scaled.reshape(-1, num_cont_feats)\n",
    "    y_pred_flat = y_pred_cont_scaled.reshape(-1, num_cont_feats)\n",
    "    \n",
    "    if not np.all(np.isfinite(y_pred_flat)):\n",
    "        logging.warning(\"Skipping detailed plots: Predicted data contains NaN/Inf.\")\n",
    "        return\n",
    "\n",
    "    y_true_unscaled = scaler.inverse_transform(y_true_flat)\n",
    "    y_pred_unscaled = scaler.inverse_transform(y_pred_flat)\n",
    "    \n",
    "    # 1. Residual Error Distribution (Graph 5/5)\n",
    "    try:\n",
    "        residuals = y_true_unscaled - y_pred_unscaled\n",
    "        residuals_df = pd.DataFrame(residuals, columns=CONTINUOUS_FEATURES)\n",
    "        residuals_melted = residuals_df.melt(var_name='Feature', value_name='Residual')\n",
    "\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        sns.violinplot(x='Feature', y='Residual', data=residuals_melted, inner='quartile', palette='coolwarm')\n",
    "        plt.title('Residual Error Distribution (Target: Centered at Zero)')\n",
    "        plt.xlabel('Continuous Feature')\n",
    "        plt.ylabel('Prediction Residual (True - Predicted)')\n",
    "        plt.axhline(0, color='black', linestyle='--')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_path, 'conv1d_residual_distribution.png'))\n",
    "        plt.close()\n",
    "        logging.info(\"Graph 5/5: Residual error distribution plot saved.\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping residual distribution plot due to error: {e}\")\n",
    "        \n",
    "    # 2. True vs. Predicted Unscaled Time Series Reconstruction (Graph 4/5)\n",
    "    try:\n",
    "        # Select one patient's full series for visualization\n",
    "        patient_idx = np.random.randint(0, len(X_val))\n",
    "        \n",
    "        # We need a better way to map sequence index to patient ID for a full time series, \n",
    "        # but for simplicity, we plot a random sequence window\n",
    "        \n",
    "        # Plot one sequence reconstruction for one feature\n",
    "        seq_idx = np.random.randint(0, len(X_val))\n",
    "        feature_idx = CONTINUOUS_FEATURES.index('Heart Rate') # Choose a representative feature\n",
    "        \n",
    "        true_sequence = y_true_cont_scaled[seq_idx, :, feature_idx]\n",
    "        pred_sequence = y_pred_cont_scaled[seq_idx, :, feature_idx]\n",
    "\n",
    "        # Rescale the 3 time points (t-2, t-1, t) for the selected feature\n",
    "        dummy_array = np.zeros((3, num_cont_feats))\n",
    "        dummy_array[:, feature_idx] = true_sequence\n",
    "        true_unscaled = scaler.inverse_transform(dummy_array)[:, feature_idx]\n",
    "        \n",
    "        dummy_array[:, feature_idx] = pred_sequence\n",
    "        pred_unscaled = scaler.inverse_transform(dummy_array)[:, feature_idx]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        time_points = [f't-{OPTIMIZED_CONFIG[\"SEQUENCE_LENGTH\"]-1}', f't-{OPTIMIZED_CONFIG[\"SEQUENCE_LENGTH\"]-2}', 't']\n",
    "        \n",
    "        plt.plot(time_points, true_unscaled, 'b-o', label='True Value')\n",
    "        plt.plot(time_points, pred_unscaled, 'r--x', label='FL-DP Prediction')\n",
    "        \n",
    "        plt.title(f'Conv1D-AE Reconstruction for Heart Rate (Example Sequence)')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Heart Rate (Unscaled)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=':', alpha=0.6)\n",
    "        plt.savefig(os.path.join(save_path, 'conv1d_sequence_reconstruction.png'))\n",
    "        plt.close()\n",
    "        logging.info(\"Graph 4/5: Sequence reconstruction plot saved.\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping sequence reconstruction plot due to error: {e}\")\n",
    "\n",
    "\n",
    "def plot_metrics_and_ablation(full_results, save_path, epsilon, delta, sigma, best_fl_model, X_val, scaler, all_features):\n",
    "    \"\"\"Plots convergence, RMSE comparison, and performance ratio (Graphs 1-3).\"\"\"\n",
    "    data_for_plot = []\n",
    "    fl_histories = [item['training_history'] for item in full_results if item['Type'] == 'FL' and item['training_history']]\n",
    "    \n",
    "    conv1d_fl_history = next((hist for hist in fl_histories if hist and hist[0].get('model') == 'Conv1D-AE'), fl_histories[0] if fl_histories else [])\n",
    "\n",
    "    for result in full_results:\n",
    "        data_for_plot.append({\n",
    "            'Model': result['Model'],\n",
    "            'Type': result['Type'],\n",
    "            'RMSE': result['rmse'],\n",
    "            'MAE': result['mae']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data_for_plot).dropna(subset=['RMSE'])\n",
    "    \n",
    "    # 1. Federated Convergence Plot \n",
    "    try:\n",
    "        if conv1d_fl_history:\n",
    "            rounds = [h['round'] for h in conv1d_fl_history if np.isfinite(h['val_rmse'])]\n",
    "            val_rmse_unscaled = [h['val_rmse'] for h in conv1d_fl_history if np.isfinite(h['val_rmse'])]\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(rounds, val_rmse_unscaled, label=f'{conv1d_fl_history[0][\"model\"]} (FL-DP)', marker='s', linestyle='-', color='green')\n",
    "            \n",
    "            plt.title('Graph 1/5: Federated Model Convergence (Validation Unscaled)')\n",
    "            plt.xlabel('Global Communication Round')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle=':', alpha=0.6)\n",
    "            plt.savefig(os.path.join(save_path, 'fl_convergence_plot.png'))\n",
    "            plt.close()\n",
    "            logging.info(f\"Graph 1/5: Convergence plot saved.\")\n",
    "        else:\n",
    "            logging.warning(\"Skipping convergence plot: No valid FL training history found.\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping convergence plot due to error: {e}\")\n",
    "\n",
    "    # 2. Final Metric Comparison Plot (RMSE - All Models)\n",
    "    try:\n",
    "        if not df.empty:\n",
    "            df_rmse = df[['Model', 'Type', 'RMSE']].pivot(index='Model', columns='Type', values='RMSE').sort_values(by='FL', ascending=False, na_position='first')\n",
    "            \n",
    "            plt.figure(figsize=(12, 7))\n",
    "            df_rmse.plot(kind='bar', ax=plt.gca(), rot=0, color={'Centralized': 'darkred', 'FL': 'darkgreen'})\n",
    "            \n",
    "            plt.title('Graph 2/5: Ablation & Utility: RMSE Comparison (Centralized vs. FL-DP)')\n",
    "            plt.ylabel('RMSE (Unscaled Data)')\n",
    "            plt.xlabel('Model Architecture')\n",
    "            plt.legend(title='Training Type')\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(save_path, 'multi_model_rmse_comparison.png'))\n",
    "            plt.close()\n",
    "            logging.info(f\"Graph 2/5: Multi-model RMSE comparison plot saved.\")\n",
    "        else:\n",
    "            logging.warning(\"Skipping RMSE comparison plot: Results DataFrame is empty.\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping multi-model comparison plot due to error: {e}\")\n",
    "\n",
    "    # 3. Performance Ratio Plot (Critical for FL paper)\n",
    "    try:\n",
    "        if not df.empty:\n",
    "            ratios = {}\n",
    "            for model_name in df['Model'].unique():\n",
    "                cent_results = df[(df['Model'] == model_name) & (df['Type'] == 'Centralized')]\n",
    "                fl_results = df[(df['Model'] == model_name) & (df['Type'] == 'FL')]\n",
    "                \n",
    "                if not cent_results.empty and not fl_results.empty:\n",
    "                    cent_rmse = cent_results['RMSE'].iloc[0]\n",
    "                    fl_rmse = fl_results['RMSE'].iloc[0]\n",
    "                    if np.isfinite(cent_rmse) and np.isfinite(fl_rmse) and cent_rmse != 0:\n",
    "                        ratios[model_name] = fl_rmse / cent_rmse\n",
    "                    else:\n",
    "                        ratios[model_name] = float('nan')\n",
    "                \n",
    "            ratio_df = pd.DataFrame(ratios.items(), columns=['Model', 'Ratio']).dropna(subset=['Ratio']).sort_values(by='Ratio')\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='Model', y='Ratio', data=ratio_df, palette=\"coolwarm\", ax=plt.gca())\n",
    "            \n",
    "            plt.axhline(1.0, color='grey', linestyle='--', label='Ideal Ratio (1.0x)')\n",
    "            plt.axhline(1.5, color='orange', linestyle=':', label='Good Threshold (1.5x)')\n",
    "            \n",
    "            if epsilon < float('inf'):\n",
    "                privacy_text = f'Privacy Guarantee: ($\\epsilon$={epsilon:.2f}, $\\\\delta$={delta}, $\\sigma$={sigma})'\n",
    "            else:\n",
    "                privacy_text = f'Privacy Guarantee: Calculation Failed ($\\epsilon$=inf)'\n",
    "                \n",
    "            plt.text(0.98, 0.98, privacy_text, transform=plt.gca().transAxes, fontsize=10, \n",
    "                     verticalalignment='top', horizontalalignment='right', \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", alpha=0.7))\n",
    "                     \n",
    "            plt.title('Graph 3/5: Model Performance Ratio (FL RMSE / Centralized RMSE)')\n",
    "            plt.ylabel('Performance Ratio')\n",
    "            plt.xlabel('Model Architecture')\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            max_ratio = ratio_df['Ratio'].max()\n",
    "            if max_ratio > 4.0:\n",
    "                 plt.ylim(0, 4.0) \n",
    "                 plt.text(0.5, 0.95, f\"Y-Axis Capped at 4.0 (Max Ratio: {max_ratio:.2f}x)\", transform=plt.gca().transAxes, fontsize=10, \n",
    "                          verticalalignment='top', horizontalalignment='center', color='red')\n",
    "            else:\n",
    "                 plt.ylim(0, max(max_ratio * 1.1, 2.0))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(save_path, 'performance_ratio_plot.png'))\n",
    "            plt.close()\n",
    "            logging.info(f\"Graph 3/5: Performance ratio plot saved.\")\n",
    "        else:\n",
    "            logging.warning(\"Skipping performance ratio plot: Results DataFrame is empty.\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping performance ratio plot due to error: {e}\")\n",
    "\n",
    "    # Call the new detailed plot function for the best model (Conv1D-AE)\n",
    "    if best_fl_model and best_fl_model.name == 'Conv1D-AE':\n",
    "        plot_detailed_conv1d_performance(best_fl_model, X_val, scaler, all_features, save_path)\n",
    "\n",
    "\n",
    "def print_results_summary(full_results, data_stats, preproc_metadata, epsilon, delta, sigma):\n",
    "    \"\"\"Prints the final summary table.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"OPTIMIZED PIPELINE - MULTI-MODEL RESULTS SUMMARY (Utility Focus)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results_df = pd.DataFrame(full_results)\n",
    "    \n",
    "    ratios = {}\n",
    "    best_fl_rmse_for_ratio = float('inf')\n",
    "    best_model_name = \"N/A\"\n",
    "    \n",
    "    for model in results_df['Model'].unique():\n",
    "        cent_results = results_df[(results_df['Model'] == model) & (results_df['Type'] == 'Centralized')]\n",
    "        fl_results = results_df[(results_df['Model'] == model) & (results_df['Type'] == 'FL')]\n",
    "        \n",
    "        if not cent_results.empty and not fl_results.empty:\n",
    "            cent_rmse = cent_results['rmse'].iloc[0]\n",
    "            fl_rmse = fl_results['rmse'].iloc[0]\n",
    "            if np.isfinite(cent_rmse) and np.isfinite(fl_rmse) and cent_rmse != 0:\n",
    "                ratio = fl_rmse / cent_rmse\n",
    "                ratios[model] = ratio\n",
    "                if ratio < best_fl_rmse_for_ratio:\n",
    "                    best_fl_rmse_for_ratio = ratio\n",
    "                    best_model_name = model\n",
    "            else:\n",
    "                ratios[model] = float('nan')\n",
    "        else:\n",
    "            ratios[model] = float('nan')\n",
    "        \n",
    "    results_df['Ratio'] = results_df['Model'].map(ratios)\n",
    "    \n",
    "    display_df_raw = results_df.pivot_table(index='Model', columns='Type', values=['rmse', 'mae']).reset_index()\n",
    "    display_df_raw.columns = ['Model', 'Cent. MAE', 'FL MAE', 'Cent. RMSE', 'FL RMSE']\n",
    "    display_df = display_df_raw[['Model', 'Cent. RMSE', 'FL RMSE', 'Cent. MAE', 'FL MAE']]\n",
    "    \n",
    "    display_df['Ratio (FL/Cent)'] = display_df['Model'].map(ratios).apply(lambda x: f'{x:.2f}x' if np.isfinite(x) else 'N/A')\n",
    "    \n",
    "    print(\"MODEL PERFORMANCE (UNSCALED METRICS):\")\n",
    "    print(display_df.to_markdown(index=False, floatfmt=\".4f\"))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "    print(\"\\nDIFFERENTIAL PRIVACY & FEATURE SUMMARY:\")\n",
    "    if epsilon < float('inf'):\n",
    "        privacy_assessment = 'STRONG' if epsilon <= 5.0 else 'GOOD' if epsilon <= 15.0 else 'MODERATE'\n",
    "        print(f\"  Total Privacy Budget: ($\\epsilon$={epsilon:.4f}, $\\delta$={delta})\") \n",
    "    else:\n",
    "        privacy_assessment = \"CALCULATION FAILED\"\n",
    "        print(f\"  Total Privacy Budget: ($\\epsilon$=inf, $\\delta$={delta})\")\n",
    "    \n",
    "    print(f\"  Noise Multiplier ($\\sigma$): {sigma}\")\n",
    "    print(f\"  Assessment: {privacy_assessment} Privacy Guarantee\")\n",
    "    \n",
    "    print(\"\\nDATA STATISTICS:\")\n",
    "    print(f\"  Total Observations: {data_stats['total_observations']}\")\n",
    "    print(f\"  Sequences (Approximate): {preproc_metadata['total_sequences']}\")\n",
    "    print(f\"  Input Shape (Sequence Length, Total Features): {preproc_metadata['input_shape']}\")\n",
    "    print(f\"  Continuous Features ({preproc_metadata['continuous_feature_count']}): {', '.join(data_stats['continuous_features'])}\")\n",
    "    print(f\"  Categorical Features ({preproc_metadata['categorical_feature_count']}): {', '.join(data_stats['categorical_features'])}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "def run_optimized_pipeline():\n",
    "    start_time = datetime.now()\n",
    "    output_dir = Path(\"optimized_fhir_research\") / f\"multi_model_{start_time.strftime('%Y%m%dT%H%M%S')}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logging.info(\"=== Phase 1: Data Loading (Multi-Feature) ===\")\n",
    "    data_df, data_stats = load_fhir_data()\n",
    "\n",
    "    logging.info(\"=== Phase 2: Data Preprocessing (Multi-Feature) ===\")\n",
    "    X_train, X_val, client_datasets, scaler, preproc_metadata, val_patient_data = preprocess_data(data_df, OPTIMIZED_CONFIG)\n",
    "    input_shape = preproc_metadata['input_shape']\n",
    "    all_features = preproc_metadata['feature_names']\n",
    "    \n",
    "    total_rounds = OPTIMIZED_CONFIG['GLOBAL_ROUNDS']\n",
    "    dp_sigma = OPTIMIZED_CONFIG['DP_SIGMA']\n",
    "    dp_delta = OPTIMIZED_CONFIG['DELTA']\n",
    "    dp_q = OPTIMIZED_CONFIG['SAMPLING_Q']\n",
    "    \n",
    "    # Calculate Privacy Budget\n",
    "    alpha, epsilon = calculate_dp_epsilon(dp_sigma, dp_q, total_rounds, dp_delta)\n",
    "    \n",
    "    full_results = []\n",
    "    best_fl_model = None\n",
    "    \n",
    "    logging.info(\"=== Phase 3: Optimized Multi-Model Training (Centralized and Federated) ===\")\n",
    "\n",
    "    for model_name, model_creator in MODEL_CREATORS.items():\n",
    "        logging.info(f\"--- Training {model_name} ---\")\n",
    "\n",
    "        # 1. Centralized Training\n",
    "        _, cent_rmse, cent_mae = train_centralized_model(X_train, X_val, input_shape, OPTIMIZED_CONFIG, scaler, model_creator, all_features)\n",
    "        \n",
    "        full_results.append({'Model': model_name, 'Type': 'Centralized', 'rmse': cent_rmse, 'mae': cent_mae, 'training_history': []})\n",
    "\n",
    "        # 2. Federated Training (with DP)\n",
    "        fl_trainer = FLCentralTrainer(OPTIMIZED_CONFIG, input_shape, scaler, model_creator, all_features)\n",
    "        fl_model, fl_rmse, fl_mae = fl_trainer.train(client_datasets, X_val)\n",
    "        \n",
    "        full_results.append({'Model': model_name, 'Type': 'FL', 'rmse': fl_rmse, 'mae': fl_mae, 'training_history': fl_trainer.training_history})\n",
    "        \n",
    "        # Keep track of the best model (Conv1D-AE) for detailed plotting\n",
    "        if model_name == 'Conv1D-AE':\n",
    "             best_fl_model = fl_model\n",
    "    \n",
    "    logging.info(\"OPTIMIZED multi-model pipeline completed! Results saved to: \" + str(output_dir))\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Phase 4: Summarize and Plot\n",
    "    # ---------------------------\n",
    "    plot_metrics_and_ablation(full_results, output_dir, epsilon, dp_delta, dp_sigma, best_fl_model, X_val, scaler, all_features)\n",
    "    print_results_summary(full_results, data_stats, preproc_metadata, epsilon, dp_delta, dp_sigma)\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# ---------------------------\n",
    "# Run the optimized pipeline\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        run_optimized_pipeline()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Pipeline failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
